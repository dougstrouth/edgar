# --- EDGAR Project Environment Variables ---
# This is an example file. For the application to work, you must:
# 1. Copy this file to a new file named ".env" in the same directory.
# 2. Customize the paths below for your system if desired.

# --- Core Paths (Required) ---
# Directory where all downloaded files (zips, json) will be stored.
# Use absolute paths to avoid ambiguity. The script will create this directory.
# Example for Windows: DOWNLOAD_DIR=C:\data\edgar_project\downloads
# Example for Linux/macOS: DOWNLOAD_DIR=/data/edgar_project/downloads
DOWNLOAD_DIR=C:\Users\user\Documents\edgar_data\downloads

# Path to the DuckDB database file. The file will be created if it doesn't exist.
# The directory containing the file must be writable.
# Example for Windows: DB_FILE=C:\data\edgar_project\db\edgar_analytics.duckdb
# Example for Linux/macOS: DB_FILE=/data/edgar_project/db/edgar_analytics.duckdb
DB_FILE=C:\Users\user\Documents\edgar_data\db\edgar_analytics.duckdb

# --- SEC EDGAR API Settings (Required) ---
# The SEC requires a custom User-Agent for all API requests.
# Format: "YourCompanyName YourAppName YourContactEmail@example.com"
SEC_USER_AGENT="PersonalResearchProject your.email@example.com"


# --- Optional Script-Specific Settings ---
# You can uncomment and change these to control the behavior of specific scripts.

# === edgar_data_loader.py ===
# Limit the number of CIKs to process. Useful for testing. Comment out to process all.
# PROCESS_LIMIT=50
# Process only one specific CIK. Overrides PROCESS_LIMIT. Comment out for normal runs.
# PROCESS_SPECIFIC_CIK=0000320193
# Set the number of CIKs to parse before loading a batch to the database.
# CIK_BATCH_SIZE=25

# === stock_data_gatherer.py ===
# Number of tickers to fetch before loading a batch into the database.
# STOCK_GATHERER_BATCH_SIZE=75
# Override the start date for 'append' mode. Format: YYYY-MM-DD.
# STOCK_GATHERER_APPEND_START=2023-01-01

# === General Parallel Processing Settings ===
# Number of concurrent workers for various CPU/IO-bound tasks (e.g., JSON extraction, JSON parsing).
# MAX_CPU_IO_WORKERS=8
 
# Number of concurrent workers to use for fetching data from Yahoo Finance (used by gather-stocks and gather-info).
# YFINANCE_MAX_WORKERS=10
# A small delay (in seconds) to add between yfinance requests to be polite to the API.
# YFINANCE_REQUEST_DELAY=0.05

# --- API Keys (Required for certain gatherers) ---
# API Key for Federal Reserve Economic Data (FRED).
# Get a free key from: https://fred.stlouisfed.org/docs/api/api_key.html
# FRED_API_KEY=your_key_here


# --- Performance & Tuning ---
# DuckDB memory limit for heavy operations like loading and indexing.
# DUCKDB_MEMORY_LIMIT=8GB

# Optional: A directory for DuckDB to spill to disk if the memory limit is exceeded.
# DUCKDB_TEMP_DIR=/path/to/your/duckdb_temp

# Number of concurrent workers for CPU/IO-bound tasks (e.g., JSON parsing).
# MAX_CPU_IO_WORKERS=8
